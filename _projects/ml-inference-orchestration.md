---
layout: project
title: "ML Inference Pipeline Orchestration"
subtitle: "Deep RL for edge computing optimization"
date: 2021-06-01
period: "Jun 2021 - Sep 2021"
status: "completed"
technologies: ["Python", "PyTorch", "Deep RL", "DQN", "Edge Computing"]
---

## Project Overview

Developed an orchestrating system for complex ML inference pipelines using deep reinforcement learning during research internship at Nokia Bell Labs, Cambridge, UK.

## Research Context

- **Institution:** Nokia Bell Labs
- **Location:** Cambridge, UK
- **Mentors:** Dr. Chulhong Min and Dr. Fahim Kawsar
- **Focus:** Edge computing and ML inference optimization

## Technical Approach

### Deep Q-Network (DQN) Architecture

- **State:** Current queue status across heterogeneous hardware
- **Action:** Queue selection for incoming inference requests
- **Reward:** Throughput optimization and latency minimization

### System Design

Designed video analytics request orchestration system that:
- Manages complex ML inference pipelines across edge devices
- Optimizes for heterogeneous hardware capabilities
- Balances load across multiple processing units
- Reduces overall system latency

## Key Achievements

- Successfully implemented DQN-based orchestration system
- Improved throughput for complex ML pipelines
- Reduced inference latency in edge environments
- Demonstrated scalability across different hardware configurations

## Skills Demonstrated

- Deep reinforcement learning implementation
- Distributed systems design
- Edge computing optimization
- Real-time system performance tuning
- International research collaboration

## Research Impact

- Advanced state-of-the-art in edge ML orchestration
- Contributed to Nokia's edge computing research
- Practical application of RL in systems optimization
- Foundation for future work in adaptive ML systems